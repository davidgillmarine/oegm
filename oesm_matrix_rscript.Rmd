---
title: "OEGM script"
author: "David A. Gill & Dana I. Grieco"
date: "3/15/2024"
output: html_document
---
# Note for Others:
If you use this script, please acknowledge David A. Gill, Samantha H. Cheng, and Dana I. Grieco in your paper. Thank you!

#Before Beginning: Update R and R Studio

##Updating R Studio
Go to 'Help' > 'Check for Updates' to install newest version

## Updating R
First, check your current version of R, and see if it is the same or behind the current version listed at https://cran.r-project.org/bin/windows/base/
```{r echo=FALSE, warning=FALSE, include=FALSE, eval=FALSE}
sessionInfo()
```
If you do need to update r, install the installr package if you don’t have it.
```{r echo=FALSE, warning=FALSE, include=FALSE, eval=FALSE}
# installing/loading the package:
# if(!require(installr)) {
#   install.packages("installr"); 
#   require(installr)
# } #load / install+load installr
```
Then call updateR() function to call update. This will start the updating process of your R installation. It will check for newer versions, and if one is available, will guide you through the decisions you’d need to make.
  *Note: R studio might direct you to use updateR() in R Gui. If it does, you will need to load installr 'library(installr)' IN R Gui before updating.*
```{r echo=FALSE, warning=FALSE, eval=FALSE, include=FALSE}
# using the package:
 # updateR()
```
**After you update R, make sure to DELETE the old version of R from your computer!** Otherwise, R Studio will just stay attached to the old version of R.

# Install Pacman IF you've updated R
[Pacman](http://trinker.github.io/pacman/vignettes/Introduction_to_pacman.html) is a package management tool. The most important part of this package is that it will install and load packages (install.packages() and library()) by only using p_load(). It can also load and install github packages using p_load_git(). It also can update packages (update.packages) using p_update OR using the update option. The biggest draw is that Pacman can do this for ALL packages at once! :)
 
```{r installing load pacman, echo=FALSE, include=FALSE, eval=FALSE}
# install.packages("pacman")
# use this package to load other packages, re-download if updated R. don't need to load it itself - use it with pacman::function to do this
```
### A note for installation:
With installing and updating packages, remember that you can also use Tools > Check for Package updates and the packages tab (in the bottom right console window) > updates to make sure all of the packages are up to date and update any packages that need updating!

# Setup
Loads libraries, reads in data, cleans datasets
```{r eval=T}
#set working directory to the correct folders on your machine
workdir <- "R:/Gill/research/oegm/"
inputdir <- paste0(workdir,"tables/raw/")
mapdir <-  paste0(workdir,"spatial/raw/")
plotdir <- paste0(workdir,"output/plots/")
tabledir <- paste0(workdir,"output/tables/")

library(pacman) # I shouldn't need to do this, but pacman NEVER works for me with the :: below, so I need to add this
pacman::p_load(rmarkdown, broom, rio,treemap,gtools,cowplot,rnaturalearth,rnaturalearthdata,devtools,sf,rnaturalearthhires,tidyverse,dplyr)
  #WARNING: package ‘rgeos’ is not available for this version of R - take out? I think this is the OLD world map!
  # MAKE SURE rnaturalearthhires loads - installed via github -  devtools::install_github("ropensci/rnaturalearthhires")

today.date <- gsub("-","",Sys.Date())
```

## Triple-Check that Packages are Loaded
```{r double-check installation, echo=FALSE, warning=FALSE, include=FALSE, eval=FALSE}
# check to make sure packages don't need updates
old.packages()
  # this will list all packages where update is available

#update all available packages, without prompts for permission/clarification
update.packages(ask=FALSE)
```
#if old packages aren't updating, then go to Session > Restart R, and then run this chunk before going back to the top of the script
  otherwise, they can do the "package in use, won't update" situation

# Organize data

```{r eval=T}

#read in data, skip first 2 rows
all.data<-import(paste0(inputdir,"20240315_All_Papers.xlsx"), which="FULL Data Extraction Sheet",skip =2, .name_repair = "universal") %>% 
  mutate(Date=as.character(Date))

country <- import(paste0(inputdir,"allcountries.csv"))
  # OLD country datafile, but will still be useful!

# Count total papers in Full Text Screening
length(unique(all.data$Article.ID)) # should be 779 (as of 3/15/24)

# Count Rejected Papers
Reject_data <- all.data %>%  
  filter(Full.text.screening.=="Reject") %>% 
  rename(Why_rejected=If.rejected..why.,PICO_details=Further.PICO.Details, aid=Article.ID,study.ctry=Country.ies..of.study)
length(unique(Reject_data$aid)) #= how many rejected papers # should be 608 (as of 3/15/24)

# Select accepted papers, rename variables==
data_all <- all.data %>%  
  filter(Full.text.screening.=="Accept" & !is.na(Intervention.category) & !is.na(Outcome.category)) %>% 
  rename(Int_cat=Intervention.category,Outcome_cat=Outcome.category, aid=Article.ID, study.ctry=Country.ies..of.study)
length(unique(data_all$aid)) # = how many accepted & completely screened papers # should be 171 (as of 3/15/24)

# read in full intervention lists
int_list<-import(paste0(inputdir,"intervention abbreviations.csv"))
out_list<-import(paste0(inputdir,"outcome abbreviations 2.csv")) #adjusted for '24 name changes

#NOTE: the DROP DOWN LISTS here, which collect ALL of the dropdowns, are taken from the ALL PAPERS Master Sheet!
drop.down.lists<-import(paste0(inputdir,"20240315_All_Papers.xlsx"), which="Dropdowns", skip =1, .name_repair = "universal")

int_sub_list <-  drop.down.lists %>% 
  select(Intervention.subcategory) %>% 
  na.omit() %>% 
  rename(int_sub=Intervention.subcategory)
out_sub_list <-  drop.down.lists %>% 
  select(Outcome.subcategory) %>% 
  na.omit() %>% 
  rename(out_sub=Outcome.subcategory) 
num.studies <- length(unique(data_all$aid)) #should again be 171

```

# CLEAN UP Rejected at Full Text Paper Data

```{r eval=T}
# If Rejected, Why?!
unique(Reject_data$Why_rejected)  # Separate ;, then count each group

## Update Fields to get stats for each category (without semicolon (;) confusion)
Reject_data <- Reject_data %>% 
mutate(OtherReason=ifelse(grepl("Other Reason",Why_rejected,ignore.case = T),1,0), # note: ignores case, so the lowercase is fine!
       Doesnt_fit_PICO=ifelse(grepl("Doesn't fit PICO/Inclusion Criteria",Why_rejected,ignore.case = T),1,0), 
       Could_not_locate=ifelse(grepl("Could not locate",Why_rejected,ignore.case = T),1,0), 
       Not_accessible=ifelse(grepl("Not accessible",Why_rejected,ignore.case = T),1,0), 
       Review_or_MA=ifelse(grepl("Reviews/Meta-Analysis",Why_rejected,ignore.case = T),1,0), 
       Duplicate=ifelse(grepl("Duplicate",Why_rejected,ignore.case = T),1,0), 
       Non_English=ifelse(grepl("Non-English Language",Why_rejected,ignore.case = T),1,0),)

## check Why Rejected Coding
unique(Reject_data$Why_rejected[Reject_data$OtherReason==1])
unique(Reject_data$Why_rejected[Reject_data$Doesnt_fit_PICO==1])
unique(Reject_data$Why_rejected[Reject_data$Could_not_locate==1])
unique(Reject_data$Why_rejected[Reject_data$Not_accessible==1])
unique(Reject_data$Why_rejected[Reject_data$Review_or_MA==1])
unique(Reject_data$Why_rejected[Reject_data$Duplicate==1])
unique(Reject_data$Why_rejected[Reject_data$Non_English==1])
  # Correct? yes

Why_rejected.test <- Reject_data %>% 
  filter(OtherReason==0 & Doesnt_fit_PICO==0 & Could_not_locate==0 & Not_accessible==0 & Review_or_MA==0 & Duplicate==0 & Non_English==0) %>% 
  select(Why_rejected)
unique(Why_rejected.test$Why_rejected) # should just be 0 - no other categories
  # Correct? yes

# Further PICO Details (I.E intervention, outcome, etc)
unique(Reject_data$PICO_details)  # Separate ;, then count each group

## Update Fields to get stats for each category (without semicolon (;) confusion)
Reject_data <- Reject_data %>% 
mutate(Population=ifelse(grepl("Population",PICO_details,ignore.case = T),1,0), # note: ignores case, so the lowercase is fine!
       Intervention=ifelse(grepl("Intervention",PICO_details,ignore.case = T),1,0), 
       Outcome=ifelse(grepl("Outcome",PICO_details,ignore.case = T),1,0), 
       Theoretical_Modeled_Study=ifelse(grepl("Theoretical/Modeled Study Design",PICO_details,ignore.case = T),1,0), 
       Not_Peer_Reviewed=ifelse(grepl("Not Peer Reviewed",PICO_details,ignore.case = T),1,0),
       N_A=ifelse(grepl("NA",PICO_details,ignore.case = T),1,0),) 
          ## NA Studies - AKA The Paper DID Fit PICO, but something else had been wrong with it in the EARLIER column... don't worry about these!

## check Why Rejected Coding
unique(Reject_data$PICO_details[Reject_data$Population==1])
unique(Reject_data$PICO_details[Reject_data$Intervention==1])
unique(Reject_data$PICO_details[Reject_data$Outcome==1])
unique(Reject_data$PICO_details[Reject_data$Theoretical_Modeled_Study==1])
unique(Reject_data$PICO_details[Reject_data$Review_or_MA==1])
unique(Reject_data$PICO_details[Reject_data$Not_Peer_Reviewed==1])
unique(Reject_data$PICO_details[Reject_data$N_A==1])
  # Correct? yes

PICO_details.test <- Reject_data %>% 
  filter(Population==0 & Intervention==0 & Outcome==0 & Theoretical_Modeled_Study==0 & Review_or_MA==0 & Not_Peer_Reviewed==0 & N_A==0) %>% 
  select(PICO_details)
unique(PICO_details.test$PICO_details) # should just be 0 - no other categories
  # Correct? yes
```

# Clean Up Accepted Paper Data

```{r eval=T}
#--- Clean up data ----

# Re-codes intervention and outcomes fields to the correct version 
# interventions
for (i in 1:nrow(int_list)){
  num.val=paste0("^",i,"\\. *") # starts with this number
  data_all <- data_all %>% 
    mutate(Int_cat=ifelse(grepl(num.val,Int_cat),grep(num.val,int_list$Int_cat_orig,value = T),Int_cat))
}
# sub-interventions
for (i in 1:nrow(int_sub_list)){
  num.val=paste0("^",gsub("\\.(.*)","",int_sub_list$int_sub[i]))  # starts with this number
  data_all <- data_all %>% 
    mutate(Intervention.subcategory=ifelse(grepl(num.val,Intervention.subcategory),
                                           grep(num.val,int_sub_list$int_sub,value = T),Intervention.subcategory))
}
# Outcomes
for (i in 1:nrow(out_list)){
  num.val=paste0("^",i)
  data_all <- data_all %>% 
    mutate(Outcome_cat=ifelse(grepl(num.val,Outcome_cat),grep(num.val,out_list$Outcome_cat_orig,value = T),Outcome_cat))
}
# Sub-outcomes
for (i in 1:nrow(out_sub_list)){
  num.val=paste0("^",gsub("\\.(.*)","",out_sub_list$out_sub[i]))  # starts with this number
  data_all <- data_all %>% 
    mutate(Outcome.subcategory=ifelse(grepl(num.val,Outcome.subcategory),
                                           grep(num.val,out_sub_list$out_sub,value = T),Outcome.subcategory))
}
```

# TROUBLE-SHOOTING - 1/24/24!!!
here, I was troubleshooting by checking different outcome categories for coding. For example, I checked cat "1c. Yield/CPUE" and decided that some of this category should be coded in category 2, AND re-coded this category to be double-coded with 5b! I also re-checked many other outcome categories, and fixed ones that had issues (e.g. 1e. behavior, 1k body conditions, 2b species diversity, culture, knowledge, etc.)

The below script is commented off, but kept the code for how to easily check these categories, and export when I needed to dive deeper.

```{r eval=T}

# # View all Outcome Subcategories!
# unique(data_all$Outcome.subcategory)

# # CPUE (1c)
# CPUE_outcomes <- data_all %>% 
#   filter(Outcome.subcategory=="1c. Yield/CPUE")
# View(CPUE_outcomes)
# write.csv(CPUE_outcomes,paste0(tabledir,today.date,"_CPUE_outcomes.csv"))

# # 1e.BEHAVIOR!
# Behavior_out <- data_all %>% 
#   filter(Outcome.subcategory=="1e. Behavior")
# # View(Behavior_out)
# # write.csv(Behavior_out,paste0(tabledir,today.date,"_1e.csv"))
# # Now going to Get EVERY Row of data for each of the aids!
# Behavior_out_aid <- Behavior_out %>% 
#   select(aid) %>%
#   distinct(aid)
# # View(Behavior_out_aid)
# 
# # Coral Attachment Issues: Outcome 1k. Body Conditions. and 1l. Adaptability - Coral studies and issues!
# Coral_issues <- data_all %>% 
#   filter(Outcome.subcategory=="1k. Body Conditions"|
#            Outcome.subcategory=="1l. Adaptability")
# # View(Coral_issues)
# # write.csv(Coral_issues,paste0(tabledir,today.date,"_1kand1l_outcomes.csv"))
# 
# # 2b. Species Diversity - Undercoded
# ## For Species Diversity, I will be pulling out SPECIFIC AIDs First (to check those)
# Diversity_issues <- data_all %>% 
#   filter(aid=="508"|
#            aid=="196"|
#            aid=="193"|
#            aid=="606"|
#          )
# # View(Diversity_issues)
# # write.csv(Diversity_issues,paste0(tabledir,today.date,"_Diversity_outcomes.csv"))
# # Now I really need to Search for ALL Species Diversity Papers - GO back and do a complete run-through
# Diversity_CODED <- data_all %>% 
#   filter(Outcome.subcategory=="2b. Species Diversity") %>% 
#   select(aid) %>%
#   distinct(aid)
# # View(Diversity_CODED)
# # write.csv(Diversity_CODED,paste0(tabledir,today.date,"_diversity.csv"))
# 
# # NEXT, I will want to pull out the Social Outcome papers, and get all of their AIDS
# 
# # KNOWLEDGE (6a)!
# know_out <- data_all %>% 
#   filter(Outcome.subcategory=="6a. Knowledge")
# # View(know_out)
# # write.csv(know_out,paste0(tabledir,today.date,"_6a_knowledge.csv"))
# 
# # Behavior/Response to new practice (6b)!
# behave_out <- data_all %>% 
#   filter(Outcome.subcategory=="6b. Behavior/response to new practices or technologies")
# # View(behave_out)
# # write.csv(behave_out,paste0(tabledir,today.date,"_6b_behavior.csv"))
# 
# # Culture(5h) - also looking for WTP
# culture_out <- data_all %>% 
#   filter(Outcome.subcategory=="5h. Culture")
# # View(culture_out)
# # write.csv(culture_out,paste0(tabledir,today.date,"_5h_culture.csv"))
```

# Quick Checks to make sure data is sorting correctly

```{r eval=T}
#quick checks
unique(data_all$Int_cat)  # 9 Interventions (we took #8 out)
unique(data_all$Outcome_cat) # 7 outcomes
sort(unique(data_all$Intervention.subcategory)) # 32 sub-interventions (in int_sub_list)
  # Only 26 sub-interventions were coded for
sort(unique(data_all$Outcome.subcategory)) # 43 sub-outcomes (bc we added in Catch/Yield x2)
  # Only 41 sub-interventions were coded for

# those that were not observed
int_list$Int_cat_orig[!int_list$Int_cat_orig%in%data_all$Int_cat] # 8. Research and monitoring
int_sub_list$int_sub[!int_sub_list$int_sub%in%data_all$Intervention.subcategory] # 6 sub-interventions. Correct: 32-26=6
out_list$Outcome_cat_orig[!out_list$Outcome_cat_orig%in%data_all$Outcome_cat] #correct, 0 bc all were coded for
out_sub_list$out_sub[!out_sub_list$out_sub%in%data_all$Outcome.subcategory] # 2 sub-outcomes. Correct: 43-41=2

# incorrect values entered (all should be zero)
data_all$Int_cat[!data_all$Int_cat%in%int_list$Int_cat_orig] #0
data_all$Intervention.subcategory[!data_all$Intervention.subcategory%in%int_sub_list$int_sub] #0
data_all$Outcome_cat[!data_all$Outcome_cat%in%out_list$Outcome_cat_orig] #0
data_all$Outcome.subcategory[!data_all$Outcome.subcategory%in%out_sub_list$out_sub] #0
  # Correct - all are 0!

# Add habitat fields
unique(data_all$Habitat.type) 
data_all <- data_all %>% 
mutate(coral=ifelse(grepl("Coral",Habitat.type,ignore.case = T),1,0),
       seagrass=ifelse(grepl("Seagrass",Habitat.type,ignore.case = T),1,0), 
       # note: ignores case, so the lowercase "seagrass" is fine!
       mangrove=ifelse(grepl("Mangrove",Habitat.type,ignore.case = T),1,0),)

# check habitat coding
unique(data_all$Habitat.type[data_all$coral==1])
unique(data_all$Habitat.type[data_all$seagrass==1])
unique(data_all$Habitat.type[data_all$mangrove==1])
  # Correct - all sorted

habitat.test <- data_all %>% 
  filter(coral==0 & mangrove==0 & seagrass==0) %>% 
  select(Habitat.type)
unique(habitat.test$Habitat.type) # should just be 0 - no other categories (we took out the "Other" category)

# remove 8. Research and Monitoring as an intervention entirely, and adjust numbers
data_all <-data_all %>% 
  filter(Int_cat!="8. Research & monitoring")%>% 
  mutate_at(vars(Int_cat,Intervention.subcategory), ~gsub("^9","8",.)) %>% 
  mutate_at(vars(Int_cat,Intervention.subcategory), ~gsub("^10","9",.))  

#new quick checks
unique(data_all$Int_cat)  # 9 interventions, #1-9
unique(data_all$Outcome_cat) # 7 outcomes, #1-7
sort(unique(data_all$Intervention.subcategory)) # 26 sub-interventions coded - no.1-9
sort(unique(data_all$Outcome.subcategory)) # 41 sub-outcomes coded, no.1-7.

# Get full intervention list
  int_list <- data_all %>%
    ungroup() %>%
    distinct(Int_cat) %>%
    rename(int_val=Int_cat) %>% 
    arrange(int_val)
  out_list <- data_all %>%
    ungroup() %>%
    distinct(Outcome_cat) %>%
    rename(out_val=Outcome_cat) %>% 
    arrange(out_val)
# Get full sub-intervention list
  int_sub_list <- data_all %>%
    ungroup() %>%
    distinct(Intervention.subcategory) %>%
    rename(int_val=Intervention.subcategory) %>% 
    arrange(int_val)
  out_sub_list <- data_all %>%
    ungroup() %>%
    distinct(Outcome.subcategory) %>%
    rename(out_val=Outcome.subcategory) %>% 
    arrange(out_val)
```

# Heat map function
Creates a heat map from the OESM accepted articles, based on intervention and outcome categories and subcategories

Under # Create Heatmap, the "geom_text" line adds text (numbers) on each heat map cell. We #ed that line for the first OEGM paper, since it was only a subsample of the literature, and thus numbers themselves could be misleading. Similarly, 

In the future, we should be able to make this heat map interactive with plotly (see https://www.r-graph-gallery.com/79-levelplot-with-ggplot2.html)

```{r eval=T}
#--- Heat map function ----
my_heat_map <- function (.data,intc, outc, high.col="#2171b5") {
  
  
# don't know why... but this works
  .data$intc<- as.vector(.data %>%  pull(intc))
  .data$outc<- as.vector(.data %>%  pull(outc))

# Set full intervention list type  
if(intc=="Int_cat"){int_list_full=int_list}
if(intc=="Intervention.subcategory"){int_list_full=int_sub_list}
if(outc=="Outcome_cat"){out_list_full=out_list}
if(outc=="Outcome.subcategory"){out_list_full=out_sub_list}

# Get unique article ID, int. and out. list (and sum of articles)
  typology_dat <- .data %>% 
    select(aid, intc, outc) %>% 
    filter(intc!="" & !is.na(intc)) %>%  # just in case
    distinct() %>% 
    full_join(int_list_full,by =c("intc"="int_val")) %>% 
    full_join(out_list_full,by =c("outc"="out_val")) %>% 
    group_by(intc) %>% 
    mutate(int_val=paste0(intc)) %>% 
      # mutate(int_val=paste0(intc," (",n_distinct(aid,na.rm = T),")")) %>%  #adds article counts to int names
    group_by(outc) %>% 
    mutate(out_val=paste0(outc)) %>% 
      # mutate(out_val=paste0(outc," (",n_distinct(aid,na.rm = T),")")) %>% #adds article counts to out names
    ungroup() %>% 
    select(-c(intc,outc)) 
  
  # Get expanded intervention-outcome list for this dataset
  int_list <- typology_dat %>%
    ungroup() %>%
    filter(int_val!="NA (0)") %>% 
    distinct(int_val) %>%
    arrange(int_val)
  out_list <- typology_dat %>%
    ungroup() %>%
    distinct(out_val) %>%
    filter(out_val!="NA (0)") %>% 
    arrange(out_val)
  io_list <- expand.grid(int_list$int_val,out_list$out_val) %>% 
    rename(int_val=Var1,out_val=Var2)

#head(io_list)
  
  #gather data and get counts 
  io_counts <<- typology_dat %>%
    group_by(int_val, out_val) %>% 
    count() %>%
    full_join(io_list,by = c("int_val", "out_val")) %>%   # inserts missing combinations
    filter(int_val!="NA (0)" &  out_val!="NA (0)") %>% 
    mutate(n=replace_na(n,0)) %>%
    ungroup() %>% 
    mutate(int_val=factor(int_val,levels=mixedsort(int_list$int_val)))  # set int list in right order
  
  # head(io_counts)
  # nrow(int_list)*nrow(out_list)==nrow(io_counts) # quick check (should be true)
  
# Create Heatmap
  heat.map <<- ggplot(data=io_counts, aes(x=int_val,y=reorder(out_val, desc(out_val)),fill=n)) +
      geom_tile(color="gray90",size=0.1) +
      # geom_text(aes(label=n),show.legend = F) + # adds numbers into cells
    scale_fill_gradient2(low="#f7fbff",high=high.col,name="Number of Studies",
        na.value="black", limits=c(0,max(io_counts$n))) + 
      coord_equal() +
      # theme_tufte(base_family="Helvetica") +	# having issues with font, font colour in windows...
      theme(axis.ticks=element_line(size=0.3),
        axis.text=element_text(size=10),
        axis.text.x = element_text(angle=45,hjust=0,vjust=1),
        axis.text.y = element_text(angle=0,hjust=0,vjust=0),
        legend.title=element_text(size=10),
        legend.title.align=1,
        legend.text=element_text(size=8),
        legend.margin = margin(grid::unit(0,"cm")),
        legend.position ="bottom",
        legend.direction ="horizontal",
        legend.key.size=grid::unit(1, "cm"),
        legend.key.width=grid::unit(1, "cm"),
        plot.background=element_blank(),
        panel.border=element_blank(),
        plot.title=element_text(hjust=0,size=12,face="bold"),
        text=element_text(family="sans")) +  # "serif"=TN Roman, "sans" = Arial
      scale_x_discrete(position = "top") +
      scale_y_discrete(position = "right") 
      #  labs(x="Conservation Intervention", y="Outcome", title ="All ecosystems") +
}
```

# Create heat maps 
```{r eval=T}
#--- Create maps ----
# All ecosystems
my_heat_map(data_all,"Int_cat","Outcome_cat")
io_counts.all <- io_counts
(heat.map.all <- heat.map +
    labs(x="Conservation Intervention", y="Outcome", title ="All ecosystems"))
ggsave(paste0(plotdir,today.date,'_int_out_map.png'),width = 8,height = 8)

# All ecosystems - Intervention subcategory X Outcome
my_heat_map(data_all,"Intervention.subcategory", "Outcome_cat")
io_counts.subint <- io_counts
(heat.map.subint <- heat.map + labs(x="Conservation Intervention", y="Outcome", title ="All ecosystems"))
ggsave(paste0(plotdir,today.date,'_sub.int_out_map.png'),width = 16,height = 8)

# All ecosystems - Intervention  X Outcome subcategory
my_heat_map(data_all,"Int_cat", "Outcome.subcategory")
io_counts.subint <- io_counts
(heat.map.subint <- heat.map + labs(x="Conservation Intervention", y="Outcome", title ="All ecosystems"))
ggsave(paste0(plotdir,today.date,'_int_sub.out_map.png'),width = 8,height = 16)

# All ecosystems - Intervention subcategory X Outcome subcategory
my_heat_map(data_all,"Intervention.subcategory", "Outcome.subcategory")
io_counts.subintout <- io_counts
(heat.map.subint <- heat.map + labs(x="Conservation Intervention", y="Outcome", title ="All ecosystems"))
ggsave(paste0(plotdir,today.date,'_sub.int_sub.out_map.png'),width = 16,height = 12)

# Coral
my_heat_map(filter(data_all,coral==1),"Int_cat","Outcome_cat", high.col = "coral3")
io_counts.coral <- io_counts
(heat.map.coral <- heat.map + labs(x="Conservation Intervention", y="Outcome", title ="Coral"))

# Mangrove
my_heat_map(filter(data_all,mangrove==1),"Int_cat","Outcome_cat", high.col = "orange2")
io_counts.mangrove <- io_counts
(heat.map.mangrove <- heat.map + labs(x="Conservation Intervention", y="Outcome", title ="Mangrove")) 

# Seagrass
my_heat_map(filter(data_all,seagrass==1),"Int_cat","Outcome_cat", high.col = "green4")
io_counts.seagrass <- io_counts
(heat.map.seagrass <- heat.map + labs(x="Conservation Intervention", y="Outcome", title ="Seagrass")) 

# Ecosystem maps on same scale
max.val <- max(io_counts.mangrove$n,io_counts.coral$n,io_counts.seagrass$n)
plot_grid(heat.map.coral + scale_fill_gradient2(low="#f7fbff",high= "coral3",name="# Cases",na.value="black", limits=c(0,max.val)),
          heat.map.seagrass + scale_fill_gradient2(low="#f7fbff",high= "green4",name="# Cases",na.value="black", limits=c(0,max.val)),
          heat.map.mangrove + scale_fill_gradient2(low="#f7fbff",high= "orange2",name="# Cases",na.value="black", limits=c(0,max.val)),
          labels=letters[1:3], ncol = 3, nrow = 1, hjust=-1, align = "hv")
ggsave(paste0(plotdir,today.date,'_habitat_int_out_map.png'),width = 17,height = 8)

# NOTE: maps might not show up below, but check folders - they should still come out fine
```
# World map
 
Step 1: Data Cleaning
 
```{r eval=T}
#---- World map ----
# Data Cleaning

# Clean and Organize Data
unique(data_all$study.ctry)

# fix data in country column
  ## the "admin" column in ne_countries joins to the country shapes from Natural Earth by name. This can get tricky because the names have to match exactly, which is what I do below
ctry.fix <- data_all %>%
  mutate(study.ctry=gsub(",",";",study.ctry),  # replace "," with ";" to help with splitting
         study.ctry=gsub("Bahamas","The Bahamas",study.ctry),
         study.ctry=gsub("Mauritiana","Mauritania",study.ctry),
         study.ctry=gsub("Saint Vincent And The Grenadines","Saint Vincent and the Grenadines",study.ctry),
         study.ctry=gsub("Timor-Leste","East Timor",study.ctry),
         study.ctry=gsub("Korea; South","South Korea",study.ctry),
         study.ctry=gsub("Turks and Caicos","Turks and Caicos Islands",study.ctry),
         study.ctry=gsub("Tanzania*.","United Republic of Tanzania",study.ctry),
             #Not sure if this will work, trying to do "Tanzania and anything after it"
             # now is doubled... not sure why, will just have a 2nd code... 
         study.ctry=gsub("United Republic of Tanzania United Republic Of","United Republic of Tanzania",study.ctry),
         study.ctry=gsub("Commonwealth of the Northern Mariana Islands","Northern Mariana Islands",study.ctry),
         study.ctry=gsub("Taiwan; Province Of China","Taiwan",study.ctry),
         study.ctry=gsub("Cote D'Ivoire","Ivory Coast",study.ctry),
         study.ctry=gsub("United States","United States of America",study.ctry),
         study.ctry=gsub("USA","United States of America",study.ctry),
         study.ctry=gsub(".*Virgin Islands","United States Virgin Islands",study.ctry),
            # Means "Virgin Islands" and anything before it - turns both "U.S. Virgin Islands" and "Virgin Islands" into above
         study.ctry=gsub("Viet Nam","Vietnam",study.ctry),
  ## Would Like a better Name / Map / Disputed... come back to
         study.ctry=gsub("Chagos currently disputed between UK and Republic of Mauritius","British Indian Ocean Territory",study.ctry),
         study.ctry=gsub(".*Hawaii)","United States of America",study.ctry),
         study.ctry=gsub(".*Palmyra Atoll near Kiribati but owned by United States of America)","United States of America",study.ctry),
         study.ctry=gsub(".*Guadeloupe)","France",study.ctry),
         study.ctry=gsub(".*Mayotte)","France",study.ctry),
         study.ctry=gsub(".*Reunion);","France",study.ctry),
  ## Want to check back on name changes / the way I'm referring to them
         study.ctry=gsub("Commonwealth of the Northern Mariana Islands","Northern Mariana Islands",study.ctry),
         study.ctry=gsub("Lao People's Democratic Republic","Laos",study.ctry),
         ) 

#Update the country data file to match two of the sites:
country2 <- country %>%
  mutate(Country=gsub("Bahamas","The Bahamas",Country)) %>% 
  mutate(code=gsub("BHM","BHS",code)) %>% #Bahamas had a dif country code in these two datasets
    #to match the name change above for this country
  add_row(Country = "British Indian Ocean Territory", Region = "Asia", code = "IOT", Subregion = "Southern Asia")
    # Note here: I picked Asia and Southern Asia because of the proximity to the Maldives
      # Next Closest were Mauritius and Seychelles, Technically Africa... hard pick...
```

# All Habitats World Map

Creates a world map of all habitats

https://ggplot2.tidyverse.org/reference/ggsf.html - geom_sf resource!
 -> https://ggplot2.tidyverse.org/reference/coord_map.html?q=worldmap#ref-examples
 
Requires rnaturalearth and tidyverse packages (loaded at the top)

```{r eval=T}

# All Habitats  World Map

ctry.all <- ctry.fix %>% 
  group_by(aid,study.ctry) %>%
  summarise() %>% 
  filter(!is.na(study.ctry))
head(ctry.all)

# get no. articles per country (and percentage) to create vector of column names for each country by counting the number of ";" 
    # thus isn't working out well... this gets 18 as the number... but it looks like this highest number is 23 (Australia)
max.ctry <- paste0("ctry",rep(1:max(str_count(ctry.all$study.ctry, ";")+1))) 

# Download country shapes from ne_countries map
world_countries <- ne_countries(
  scale = 10,
  type = "countries",
  returnclass = "sf")
# class(world_countries) # this tells me that this is an sf file and df - helpful!

# Join the Dataframe to rnaturalearth ne_countries (world_countries) 
ctry_sum <- ctry.all %>% 
  separate(study.ctry,max.ctry, sep="; ",fill="right") %>% # fill=right fills blanks with NAs
  gather("X","admin", max.ctry) %>%   #gather is a tidyr function that reshapes columns into key pairs 
      #renames "study.ctry" to "admin"
      #What does this "X" mean?! I really don't know, but it works
      #admin is the sub-country column in world_countries dataframe
  filter(!is.na(admin)) %>% 
  select(-X) %>% 
  group_by(admin) %>% 
  count() %>%     #count creates an "n" column
  mutate(pct=n/num.studies*100) %>%   #this creates the "pct" column
  arrange(desc(n))

# Countries that need to be fixed
ctry_sum$admin[!ctry_sum$admin%in%world_countries$admin]
  #Note: the NA country is AID 705 Campbell et al. - I emailed the corresponding author, they did not know the countries...

# join to full world_countries country data with OEGM data in a df
ctry_sum1 <- ctry_sum %>%  # ctry_sum is the data frame and world_countries is the sf 
  full_join(world_countries,by="admin") %>%  # full_join keeps all ROWS (even the n=0 rows!)
  mutate(n=na.replace(n,0)) 
ctry_sum1$admin[!ctry_sum1$admin%in%world_countries$admin] # any missing?

# join cntry_sum1 with the regions and continents in the old "country" dataset (again, full_join)
ctry_sum2 <- country2 %>%   
  full_join(ctry_sum1, by = c("code" = "adm0_a3")) %>% 
  select(-Country) %>%
  #select(admin,n,pct,code,Subregion,Region) %>%
  arrange(desc(n))
ctry_sum2$admin[!ctry_sum2$admin%in%world_countries$admin] # any missing? ###MANY NAs now!

# TURN THE FILE BACK INTO AN SF
ctry_sum3 <- st_as_sf(ctry_sum2)
class(ctry_sum3)
  #SUCCESS ctry_sum3 is an sf! 

# Plot study map
(study_ctry_map <- ggplot(data=ctry_sum3) +
  geom_sf(aes(fill=n), color=NA) + #note: color=NA takes out country boarders (otherwise grey)
  theme(
        panel.background = element_rect(fill = "#CCCCCC", colour = "#CCCCCC"), 
          #this grey looks deep, but it allows for better contrast with the white than gray90
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.border=element_blank(),
        plot.title=element_text(hjust=0,size=12), # face="bold"
        axis.ticks = element_blank(), 
        axis.text = element_blank(),
        axis.title = element_blank(),
        legend.title=element_text(size=10),
        legend.title.align=1,
        legend.text=element_text(size=8),
        legend.position ="bottom",
        text=element_text(family="sans") # "serif"=TN Roman, "sans" = Arial
        ) +
  scale_fill_gradient2(
    name = "Number of Studies",
    low="white",mid="#2171b5",high="#08519c", 
        #the low color here is white - allows for better contrast
        #the mid color here is the high color for the Gap Map
    midpoint=max(ctry_sum1$n)/2,     #keep ctry_sum1 - doesnt read sum3
    limits=c(0,max(ctry_sum1$n))) +
 coord_sf(xlim = c(-180, 180), ylim = c(-59, 84), expand = FALSE) )
ggsave(paste0(plotdir,today.date,'_study_country_map.png'),width = 12,height = 5)
```

# World Map - Coral

```{r eval=T}
# All Habitats  World Map
ctry.coral <- ctry.fix %>% 
  filter(coral==1) %>% 
  group_by(aid,study.ctry) %>%
  summarise() %>% 
  filter(!is.na(study.ctry))
head(ctry.coral)

# get no. articles per country (and percentage) to create vector of column names for each country by counting the number of ";" 
    # thus isn't working out well... this gets 18 as the number... but it looks like this highest number is 23 (Australia)
max.ctry.coral <- paste0("ctry",rep(1:max(str_count(ctry.all$study.ctry, ";")+1))) 

# Join the Dataframe to rnaturalearth ne_countries (world_countries) 
ctry_sum_coral <- ctry.all %>% 
  separate(study.ctry,max.ctry.coral, sep="; ",fill="right") %>% # fill=right fills blanks with NAs
  gather("X","admin", max.ctry.coral) %>%   #gather is a tidyr function that reshapes columns into key pairs 
      #renames "study.ctry" to "admin"
      #What does this "X" mean?! I really don't know, but it works
      #admin is the sub-country column in world_countries dataframe
  filter(!is.na(admin)) %>% 
  select(-X) %>% 
  group_by(admin) %>% 
  count() %>%     #count creates an "n" column
  mutate(pct=n/num.studies) %>%   #this creates the "pct" column
  arrange(desc(n))

# join to full world_countries country data with OEGM data in a df
ctry_sum_coral1 <- ctry_sum_coral %>%  # ctry_sum is the data frame and world_countries is the sf 
  full_join(world_countries,by="admin") %>%  # full_join keeps all ROWS (even the n=0 rows!)
  mutate(n=na.replace(n,0)) 

# join cntry_sum1 with the regions and continents in the old "country" dataset (again, full_join)
ctry_sum_coral2 <- country %>%   
  full_join(ctry_sum_coral1, by = c("code" = "adm0_a3")) %>% 
  select(-Country) %>%
  #select(admin,n,pct,code,Subregion,Region) %>%
  arrange(desc(n))
ctry_sum_coral2$admin[!ctry_sum_coral2$admin%in%world_countries$admin] # any missing?

# TURN THE FILE BACK INTO AN SF
ctry_sum_coral3 <- st_as_sf(ctry_sum_coral2)
class(ctry_sum_coral3)

# Plot study map
(study_ctry_map_coral <- ggplot(data=ctry_sum_coral3) +
  geom_sf(aes(fill=n), color=NA) + #note: color=NA takes out country boarders (otherwise grey)
  theme(
        panel.background = element_rect(fill = "#CCCCCC", colour = "#CCCCCC"), 
          #this grey looks deep, but it allows for better contrast with the white than gray90
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.border=element_blank(),
        plot.title=element_text(hjust=0,size=12), # face="bold"
        axis.ticks = element_blank(), 
        axis.text = element_blank(),
        axis.title = element_blank(),
        legend.title=element_text(size=10),
        legend.title.align=1,
        legend.text=element_text(size=8),
        legend.position ="bottom",
        text=element_text(family="sans") # "serif"=TN Roman, "sans" = Arial
        ) +
  scale_fill_gradient2(
    name = "Number of Studies",
    low="white",mid="darksalmon",high="coral3", 
        #the low color here is white - allows for better contrast
        #the high color here is the high color for the Gap Map
    midpoint=max(ctry_sum_coral1$n)/2,     #keep ctry_sum_coral1 - doesnt read sum3
    limits=c(0,max(ctry_sum_coral1$n))) +
 coord_sf(xlim = c(-180, 180), ylim = c(-59, 84), expand = FALSE) )
ggsave(paste0(plotdir,today.date,'_study_country_map_CORAL.png'),width = 12,height = 5)
```

# World Map - Mangrove and Seagrass

Haven't made, don't think we'll need these? Comment off for now?

# Create heat maps 
```{r eval=T}
#GAP MAP COLORS
# # Mangrove
# high.col = "orange2"
# 
# # Seagrass
# high.col = "green4"
```

# Treemapping

Outcome and Intervention tree maps

###NOTE: for website, may want to use https://d3js.org/ - interactive figures, including tree maps!!!
https://observablehq.com/@d3/treemap-stratify?intent=fork

```{r eval=T}
#---- Treemapping ----
# - Outcomes
unique(data_all$Outcome.subcategory)

outcomes2 <-data_all %>% 
  filter(!is.na(Outcome.subcategory)) %>% 
  select(aid,Outcome_cat,Outcome.subcategory) %>% 
  group_by(Outcome_cat) %>% 
  mutate(out.cat=paste0(Outcome_cat,"\n (",n_distinct(aid),")")) %>% 
  group_by(Outcome_cat,Outcome.subcategory) %>% 
  mutate(n=n_distinct(aid)) %>% 
  arrange(Outcome.subcategory)
unique(outcomes2$out.cat)

png(file=paste0(plotdir,today.date,"_outcome_treemap.png"), width=600, height=600) #switched to .png instead of .pdf
treemap(outcomes2,index=c("out.cat","Outcome.subcategory"),
        vSize="n",
        type="index",
        fontsize.labels = c(15,10),
        fontcolor.labels=c("white","black"),
        fontface.labels=c(2,1),
        bg.labels=c("transparent"),
        align.labels=list(
          c("center","top"),
          c("left","bottom")
        ),
        overlap.labels=0.5,
        inflate.labels=F,
        title="Study Outcomes")
dev.off()

# - Interventions
unique(data_all$Intervention.subcategory)

intervention2 <-data_all %>% 
  filter(!is.na(Intervention.subcategory)) %>% 
  select(aid,Int_cat,Intervention.subcategory) %>% 
  group_by(Int_cat) %>% 
  mutate(int.cat=paste0(Int_cat,"\n (",n_distinct(aid),")")) %>% 
  group_by(Int_cat,Intervention.subcategory) %>% 
  mutate(n=n_distinct(aid)) %>% 
  arrange(Intervention.subcategory)

unique(intervention2$int.cat)

png(file=paste0(plotdir,today.date,"_intervention_treemap.png"), width=600, height=600) #switched to .png instead of .pdf
treemap(intervention2,index=c("int.cat","Intervention.subcategory"),
        vSize="n",
        type="index",
        fontsize.labels = c(15,10),
        fontcolor.labels=c("white","black"),
        fontface.labels=c(2,1),
        bg.labels=c("transparent"),
        align.labels=list(
          c("center","top"),
          c("left","bottom")
        ),
        overlap.labels=0.5,
        inflate.labels=F,
        title="Study interventions")
dev.off()
```

# Studies over time 

```{r eval=T}
#---- Studies over time ----
All_time_gps <- data_all %>%
  group_by(Year.of.publication) %>% 
  summarise(pub.per.yr= n_distinct(aid)) %>% 
  ungroup() %>% 
  arrange(Year.of.publication) %>% 
  mutate(val=cumsum(pub.per.yr),
         gp="All") %>% 
  select(Year.of.publication,gp,val) %>% 
  filter(!is.na(Year.of.publication))
tail(All_time_gps)

# growth by decade
#overall
(max(All_time_gps$val)-min(All_time_gps$val))/(max(All_time_gps$Year.of.publication)-min(All_time_gps$Year.of.publication))
#1990s
(max(All_time_gps$val[All_time_gps$Year.of.publication<2000])-max(All_time_gps$val[All_time_gps$Year.of.publication<1990]))/10
#2000-2010
(max(All_time_gps$val[All_time_gps$Year.of.publication<2010])-max(All_time_gps$val[All_time_gps$Year.of.publication<2000]))/10
#2010-latest date (? Check this)
(max(All_time_gps$val)-max(All_time_gps$val[All_time_gps$Year.of.publication<2010]))/(max(All_time_gps$Year.of.publication)-2009)

Int_time_gps <-  data_all %>%
  group_by(Year.of.publication,Int_cat) %>% 
  summarise(int_per_yr= n_distinct(aid)) %>% 
  spread(Int_cat,value = int_per_yr) %>% 
  mutate_all(funs(replace(., is.na(.), 0))) %>% 
  ungroup() %>% 
  arrange(Year.of.publication) %>% 
  mutate_at(vars(-Year.of.publication),funs(cumsum(.))) %>% 
  gather("int_typ","val",-Year.of.publication) %>% 
  bind_rows(All_time_gps %>% rename(int_typ=gp))
tail(Int_time_gps)
# non-elegant way to convert units to factor in order to reorder plot legends
order.gp <- Int_time_gps %>% group_by(int_typ) %>% summarise(order_typ=max(val)) %>% arrange(desc(order_typ)) %>% pull(int_typ)
Int_time_gps <- Int_time_gps %>%  
  mutate(int_typ = factor(int_typ, levels = order.gp)) %>% 
  rename(Intervention=int_typ)

# int.cols <- c("black","blue","orangered1","yellow4","tan1")
# names(int.cols) <- order.gp

(pInt_time_gps <- ggplot(Int_time_gps)  + 
    geom_line(aes(x = Year.of.publication, y = val, group = Intervention, colour = Intervention), size = 1.3)  +
    ylab("Cumulative frequency") +
  #  scale_x_continuous(name="Year", breaks=seq(1985,2025,5)) +
  #  scale_colour_manual(values=int.cols) +
    ggtitle('Intervention') )
   # scale_y_continuous(limits=c(0,80), breaks=seq(0,80,10), labels=c("0","","20","","40","","60","","80")))

# Outcomes
out_time_gps <-  data_all %>%
  group_by(Year.of.publication,Outcome_cat) %>% 
  summarise(out_per_yr= n_distinct(aid)) %>% 
  spread(Outcome_cat,value = out_per_yr) %>% 
  mutate_all(funs(replace(., is.na(.), 0))) %>% 
  ungroup() %>% 
  arrange(Year.of.publication) %>% 
  mutate_at(vars(-Year.of.publication),funs(cumsum(.))) %>% 
  gather("out_typ","val",-Year.of.publication) %>% 
  bind_rows(All_time_gps %>% rename(out_typ=gp))
tail(out_time_gps)
# non-elegant way to convert units to factor in order to reorder plot legends
order.gp <- out_time_gps %>% group_by(out_typ) %>% summarise(order_typ=max(val)) %>% arrange(desc(order_typ)) %>% pull(out_typ)
out_time_gps <- out_time_gps %>%  
  mutate(out_typ = factor(out_typ, levels = order.gp)) %>% 
  rename(Outcome=out_typ)

# int.cols <- c("black","blue","orangered1","yellow4","tan1")
# names(int.cols) <- order.gp

(pout_time_gps <- ggplot(out_time_gps)  + 
    geom_line(aes(x = Year.of.publication, y = val, group = Outcome, colour = Outcome), size = 1.3)  +
    ylab("Cumulative frequency") +
    #  scale_x_continuous(name="Year", breaks=seq(1985,2025,5)) +
    #  scale_colour_manual(values=int.cols) +
    ggtitle('Outcome') )
# scale_y_continuous(limits=c(0,80), breaks=seq(0,80,10), labels=c("0","","20","","40","","60","","80")))
plot_grid(pInt_time_gps,pout_time_gps)
ggsave(paste0(plotdir,today.date,'_studies_over_time.png'),width = 12,height = 4)
```

# Stats Section

This section outputs a lot of the different stats used in the paper. Right now, I am just inputting them by hand, and so definitely would be useful to print out the stats I want to copy/paste and easy access

1. Basic Stats (Paper #s and %s)
```{r eval=T}
# --- Percentages --- #
# test <-  data_all %>%
#   select(aid, Int_cat, Intervention.subcategory, Outcome_cat,Outcome.subcategory)
# List of data headings
# head(data_all,0)

# Total papers in Full Text Screening
length(unique(all.data$Article.ID))

# Total Rejected Full-Text Papers
num.rejects <- length(unique(Reject_data$aid))
print(num.rejects)

# Reasons for Rejection

## List of data headings
# head(Reject_data,0)
## Note: these DO contain overlap, ie. some studies have multiple reasons for rejection!

## Could_not_locate
Reject_data %>%
  filter(Could_not_locate==1) %>% 
  summarise(Why_rejected="Could not Locate", num=n_distinct(aid), pct=num/num.rejects*100) 

## Not_accessible
Reject_data %>%
  filter(Not_accessible==1) %>% 
  summarise(Why_rejected="Not accessible", num=n_distinct(aid), pct=num/num.rejects*100)

## Non_English
Reject_data %>%
  filter(Non_English==1) %>% 
  summarise(Why_rejected="Non English Language", num=n_distinct(aid), pct=num/num.rejects*100) 

## Duplicate
Reject_data %>%
  filter(Duplicate==1) %>% 
  summarise(Why_rejected="Duplicate", num=n_distinct(aid), pct=num/num.rejects*100) 

# Important: I need to get the TOTAL number of Articles in the above 4 categories for the ROSES Diagram (aka need to make sure I am accounting for potential overlap)
Reject_data %>% 
  filter(Could_not_locate + Not_accessible + Non_English + Duplicate == 1) %>% 
  summarise(Why_rejected="TOP Roses Cat: 779 - Y",num=n_distinct(aid), pct=num/num.rejects*100)

## Review_or_MA
Reject_data %>%
  filter(Review_or_MA==1) %>% 
  summarise(Why_rejected="Reviews/Meta-Analysis", num=n_distinct(aid), pct=num/num.rejects*100) 

## Doesnt_fit_PICO
Reject_data %>%
  filter(Doesnt_fit_PICO==1) %>% 
  summarise(Why_rejected="Doesn't fit PICO or Inclusion Criteria", num=n_distinct(aid), pct=num/num.rejects*100) 

## Other Reason
Reject_data %>%
  filter(OtherReason==1) %>% 
  summarise(Why_rejected="Other Reason", num=n_distinct(aid), pct=num/num.rejects*100)

# Important: I need to get the TOTAL number of Articles in the above 3 categories for the ROSES Diagram (aka need to make sure I am accounting for potential overlap)
Reject_data %>% 
  filter(Review_or_MA + OtherReason + Doesnt_fit_PICO == 1) %>% 
  summarise(Why_rejected="TOP Roses Cat: 779 - Y",num=n_distinct(aid), pct=num/num.rejects*100)

# Important: I need to get the TOTAL number of ALL REJECTED Articles in the above 7 categories for the ROSES Diagram (aka ALL Full-text rejects - check to make sure the numbers match up)
Reject_data %>% 
  filter(Could_not_locate + Not_accessible + Non_English + Duplicate + Review_or_MA + OtherReason + Doesnt_fit_PICO == 1) %>% 
  summarise(Why_rejected="TOP Roses Cat: 779 - Z",num=n_distinct(aid), pct=num/num.rejects*100)

### THIS ONLY GIVES ME 604 Papers!!! WHY??!?!?!? NEED TO Come back to this

# Now, let's Dive into the "Doesn't Fit PICO" section:

## Population
Reject_data %>%
  filter(Population==1) %>% 
  summarise(PICO_details="Population", num=n_distinct(aid), pct=num/num.rejects*100)

## Intervention
Reject_data %>%
  filter(Intervention==1) %>% 
  summarise(PICO_details="Intervention", num=n_distinct(aid), pct=num/num.rejects*100) 

## Outcome
Reject_data %>%
  filter(Outcome==1) %>% 
  summarise(PICO_details="Outcome", num=n_distinct(aid), pct=num/num.rejects*100)

## Theoretical_Modeled_Study
Reject_data %>%
  filter(Theoretical_Modeled_Study==1) %>% 
  summarise(PICO_details="Theoretical or Modeled_Study", num=n_distinct(aid), pct=num/num.rejects*100) 

## Not_Peer_Reviewed
Reject_data %>%
  filter(Not_Peer_Reviewed==1) %>% 
  summarise(PICO_details="Not Peer Reviewed", num=n_distinct(aid), pct=num/num.rejects*100) 

#Total Accepted Full-Text studies
print(num.studies)
```

2. P: Geographies

#Note: 
Need to do the "search for term within a row" method here (that we used for countries above (in the map)), and do it for all of the following rows 

For Continent percentages, I literally added up the counts and re-divided (out of 183) for percentages. very tedious
Sums: Asia (48), Oceania (40), Central America and the Caribbean (36), Africa (34), and North America (32), South America (13), Europe (6) 

For country percentages, I used the ctry_sum2 list, and not this


Geographical scale of intervention is used

```{r eval=T}
# P: Geographies (aka intervention location)
##use data from world map I created!

# Join the Dataframe to rnaturalearth ne_countries (world_countries) 
region <- ctry.all %>% 
  separate(study.ctry,max.ctry, sep="; ",fill="right") %>% # fill=right fills blanks with NAs
  gather("X","admin", max.ctry) %>%   #gather is a tidyr function that reshapes columns into key pairs 
      #renames "study.ctry" to "admin"
      #What does this "X" mean?! I really don't know, but it works
      #admin is the sub-country column in world_countries dataframe
  filter(!is.na(admin)) %>% #weirdly doesn't remove aid 705
  select(-X) %>% 
  group_by(admin) %>%
  full_join(world_countries,by="admin") %>%  # full_join keeps all ROWS (even the n=0 rows!) - need country CODES
  filter(!is.na(aid)) %>%
  filter(!(aid == '705')) %>% # need this here to remove aid 705 - doesn't get removed with above
  select(aid, admin, adm0_a3, sovereignt, type, economy)
  
# join region with the regions and continents in the old "country" dataset (again, full_join)
region2 <- region %>% 
  left_join(country2, by = c("adm0_a3"  = "code")) %>% #left join only joins countries/territories represented in region dataset!
  select(-Country) %>%
  ungroup() #need to ungroup, because in this datafile things are still GROUPED by "admin", but I want to take OUT admin!
    #class(region2) - tip, use this if I'm having issues with the dataframe to try and understand it

# sort Subregions of represented papers!
subregion_dat <- region2 %>% 
  count(Subregion) %>%     #count creates an "n" column
  mutate(subregion.pct=n/num.studies*100) %>%   #this creates the "pct" column
  arrange(desc(n)) %>% 
  print()

# sort Regions of represented papers!
region_dat <- region2 %>% 
  count(Region) %>%     #count creates an "n" column
  mutate(region.pct=n/num.studies*100) %>%   #this creates the "pct" column
  arrange(desc(n)) %>% 
  print()
```

3. P: Habitats

```{r eval=T}
# Coral
data_all %>%
  filter(coral==1) %>% 
  summarise(habitat="Coral", num=n_distinct(aid), pct=num/num.studies*100)

# Seagrass
data_all %>%
  filter (seagrass==1) %>% 
  summarise(habitat="Seagrass", num=n_distinct(aid), pct=num/num.studies*100) 

# Mangrove
data_all %>%
  filter (mangrove==1) %>% 
  summarise(habitat="Mangrove", num=n_distinct(aid), pct=num/num.studies*100) 

# Note: these DO contain overlap, ie. some studies have multiple habitats:
# data_all %>%
#   group_by(Habitat.type) %>% 
#   summarise(num=n_distinct(aid), pct=num/num.studies*100)  %>%
#   arrange (desc(num)) 

# How many studies took place in only one of three habitats?
data_all %>% 
  filter(coral + seagrass + mangrove == 1) %>% 
  summarise(habitat="Only One",num=n_distinct(aid), pct=num/num.studies*100)

# How many studies took place in multiple habitats? (2 or more)
data_all %>% 
  filter(coral + seagrass + mangrove >= 2) %>% 
  summarise(habitat="Multiple: 2 or more!", num=n_distinct(aid), pct=num/num.studies*100)

# How many studies took place in all 3 habitats?
data_all %>% 
  filter(coral + seagrass + mangrove == 3) %>% 
  summarise(habitat="All 3 Habitats!", num=n_distinct(aid), pct=num/num.studies*100)
  
```

5. C: Comparators, Study designs used aka MANY Stats here!


```{r eval=T}

  # Primary vs Secondary Data
data_all %>%
  group_by(Primary.or.secondary.data.) %>% 
  summarise(num=n_distinct(aid), pct=num/num.studies*100)  %>%
  arrange (desc(num))  # this arranges them in descending order 

  # Type of Data
data_all %>%
  group_by(What.type.of.data.does.this.study.consider.) %>% 
  summarise(num=n_distinct(aid), pct=num/num.studies*100)  %>%
  arrange (desc(num))  # this arranges them in descending order 

  # Comparator Type
comparator.types <- data_all  %>%
  group_by(Comparator.type) %>% 
  summarise(num=n_distinct(aid), pct=num/num.studies*100)  %>%
  arrange (desc(num)) # this arranges them in descending order 
  # arrange (num) # for ascending order, swap
view(comparator.types)
##### Need to do the "search for term within a row" method here, like how we sorted the coral

#Find and look at the 5 "None" comparator studies
unique(data_all %>% 
  filter(Comparator.type== "None") %>% 
  select(aid))

  # Does the Study population considers human groups?
data_all %>%
  group_by(Does.the.study.explicitly.examine.impacts.on.different.human.groups.) %>% 
  summarise(num=n_distinct(aid), pct=num/num.studies*100)  %>%
  arrange (desc(num))  # this arranges them in descending order 

# If so, what types?
data_all %>%
  filter(!is.na(If.so..what.types.of.different.groups.)) %>% 
  group_by(If.so..what.types.of.different.groups.) %>% 
  summarise(num=n_distinct(aid), pct=num/num.studies*100)
    #  arrange (desc(num))  # this arranges them in descending order 

# Scale of Study - as related to the INTERVENTION
data_all %>%
  group_by(Scale.of.study) %>% 
  summarise(num=n_distinct(aid), pct=num/num.studies*100)  %>%
  arrange (desc(num))  # this arranges them in descending order 

```

# Looking at Fisheries Papers (as deemed by screeners!)

```{r eval=T}

# Looking at Fisheries Papers (as deemed by screeners!)

Fisheries_Papers <- data_all %>%
  filter(Fisheries.Paper. == "Yes")
# View() # spot check
# write.csv(Fisheries_Papers,paste0(tabledir,today.date,"_Fisheries_Papers.csv"))

# How many studies are Fisheries Papers?
n_distinct(data_all$aid[data_all$Fisheries.Paper. == "Yes"])

```

4. I: Interventions

```{r eval=T}
# I: Interventions
data_all %>%
  group_by(Int_cat) %>% 
  summarise(num=n_distinct(aid), pct=num/num.studies*100)  %>%
  arrange (desc(num))  # arranges them in descending order 

  # Highest: % - top 3 (tie for second highest)
data_all %>%  
  filter(Int_cat== "1. Land/water management"| 
           Int_cat== "2. Species management"| 
           Int_cat== "7. Legal & policy frameworks") %>%  
  summarise(intervention="Highest 3", num=n_distinct(aid), pct=num/num.studies*100)

  # Lowest: % - bottom 4 (tie for lowest and second lowest)
data_all %>%  
  filter(Int_cat== "3. Awareness raising "| 
           Int_cat== "5. Livelihood, economic, and other incentives"|
           Int_cat== "4. Enforcement & protection"| 
           Int_cat== "8. Education & training") %>%  
  summarise(intervention="Lowest 4", num=n_distinct(aid), pct=num/num.studies*100)

  # Subcategories (want % of each):
data_all %>%
  group_by(Intervention.subcategory) %>% 
  summarise(num=n_distinct(aid), pct=num/num.studies*100)  %>%
  arrange (desc(num))  # arranges them in descending order 
  # arrange (num) # arranges in ascending order, swap
```

# Multiple Intervention Studies

In the paper, I look at rate of integrated (multiple) intervention studies over time... I just did this by hand based on the multi_int_time_gps table created in this script


```{r eval=T}
(multi.int.studies <- data_all %>% 
    #   filter(Int_cat!="8. Research & monitoring") %>% 
    group_by(Year.of.publication,aid) %>% 
    summarise(n.int=n_distinct(Int_cat)) %>% 
   filter(n.int>1)
)

#Distinct PERCENT of Multiple Intervention Studies!
n_distinct(multi.int.studies$aid)/n_distinct(data_all$aid)*100

multi.int.aid <- multi.int.studies$aid[multi.int.studies$n.int>1]

Multi_int_time_gps <- data_all %>%
  filter(aid%in%multi.int.aid) %>% 
  group_by(Year.of.publication) %>% 
  summarise(pub.per.yr= n_distinct(aid)) %>% 
  ungroup() %>% 
  arrange(Year.of.publication) %>% 
  mutate(val=cumsum(pub.per.yr),
         gp="Multi-intervention") %>% 
  select(Year.of.publication,gp,pub.per.yr,val) %>% 
  filter(!is.na(Year.of.publication))
View(Multi_int_time_gps)

```

6. O: Outcomes:

```{r eval=T}

data_all %>%
  group_by(Outcome_cat) %>% 
  summarise(num=n_distinct(aid), pct=num/num.studies*100)%>% 
  arrange (desc(num))  # this arranges them in descending order 

# % Pop/Species and Ecological Community combined (no overlaps):
data_all %>%  
  filter(Outcome_cat== "1. Population/Species"| 
         Outcome_cat==  "2. Ecological Community") %>%  
  summarise(num=n_distinct(aid), pct=num/num.studies*100)

  # % in social: human well-being, knowledge and behavior, and governance
data_all %>%  
  filter(Outcome_cat== "5. Human Wellbeing"| 
          Outcome_cat== "6. Knowledge and Behavior"| 
          Outcome_cat== "7. Governance") %>%  
  summarise(num=n_distinct(aid), pct=num/num.studies*100)

  # % in ecosystem function and ecosystem service
data_all %>%  
  filter(Outcome_cat== "3. Ecosystem Function"| 
          Outcome_cat==  "4. Ecosystem Services") %>%  
  summarise(num=n_distinct(aid), pct=num/num.studies*100)

  # Subcategories (want % of each):
data_all %>% 
  group_by(Outcome.subcategory) %>% 
  summarise(num=n_distinct(aid), pct=num/num.studies*100) %>%
  arrange (desc(num))  # this arranges them in descending order 
  # arrange (num) # for ascending order, swap
  
```

# Interdisciplinary Outcomes

# Add eco vs soc outcome counts
```{r eval=T}
unique(data_all$Outcome_cat)
eco.outcomes <- c("2. Ecological Community", "1. Population/Species", "3. Ecosystem Function")
soc.outcomes <- c("6. Knowledge and Behavior", "5. Human Wellbeing", "7. Governance")
        
data_all <- data_all %>%
  # select(aid, Outcome_cat) %>%
  mutate(eco.out=ifelse(Outcome_cat%in%eco.outcomes,1,0),
         soc.out=ifelse(Outcome_cat%in%soc.outcomes,1,0),
         es.out=ifelse(Outcome_cat=="4. Ecosystem Services",1,0)) %>% 
  group_by(aid) %>% 
  mutate(eco.aid=max(eco.out),
            soc.aid=max(soc.out),
            es.aid=max(es.out),
            eco.soc.aid=ifelse(eco.aid+soc.aid>1,1,0),
            es.eco.soc.aid=ifelse(eco.aid+es.aid>1 | soc.aid+es.aid>1,1,0),
            interdisc.aid=ifelse(eco.soc.aid==1 | es.eco.soc.aid==1,1,0)) 

# View(select(data_all,Outcome_cat,eco.aid:interdisc.aid)) # spot check

# Which studies have both Ecological and Social outcomes? (No ecosystem services)
n_distinct(data_all$aid[data_all$eco.soc.aid == 1])

# Which studies have both Ecological and Social outcomes? (includes ecosystem services)
n_distinct(data_all$aid[data_all$interdisc.aid == 1])

# Eco_Soc_ES_Out and export csv
Eco_Soc_ES_Out <- data_all %>%
  filter(interdisc.aid == 1)
# View(select(Eco_Soc_ES_Out,Outcome_cat,eco.aid:interdisc.aid)) # spot check
write.csv(Eco_Soc_ES_Out,paste0(tabledir,today.date,"_Eco_and_Soc_and_ES_Outcomes.csv"))

```

## Interdisciplinary outcome comparison heat maps
```{r eval=T}

interd.dat <- data_all %>% 
  mutate(typ=case_when(
  soc.aid == 1 & interdisc.aid == 0 ~ "social only",
  eco.aid == 1 & interdisc.aid == 0 ~ "eco only",
  interdisc.aid == 1 ~ "interdisciplinary"),
  typ=as.factor(typ))

interd.out <- interd.dat %>% 
  group_by(Outcome_cat,typ) %>% 
  count() %>% 
  group_by(Outcome_cat) %>% 
  mutate(prop=n/sum(n)) %>% 
  filter(!is.na(typ))

interd.int <- interd.dat %>% 
  group_by(Int_cat,typ) %>% 
  count() %>% 
  group_by(Int_cat) %>% 
  mutate(prop=n/sum(n))%>% 
  filter(!is.na(typ))

plot_grid(
# ggplot(interd.out, aes(fill=typ, y=prop, x=Outcome_cat)) + 
#     geom_bar(position="stack", stat="identity") +
#     coord_flip(), 
# ggplot(interd.out, aes(fill=typ, y=n, x=Outcome_cat)) + 
#     geom_bar(position="stack", stat="identity") +
#     coord_flip(),
ggplot(interd.int, aes(fill=typ, y=prop, x=Int_cat)) + 
    geom_bar(position="stack", stat="identity") +
    coord_flip(),
ggplot(interd.int, aes(fill=typ, y=n, x=Int_cat)) + 
    geom_bar(position="stack", stat="identity") +
    coord_flip(),
 nrow=2)

Eco_Soc_ES_Out <- data_all %>%
  filter(interdisc.aid == 1)

# All ecosystems all  vs interdisc. studies
my_heat_map(Eco_Soc_ES_Out,"Int_cat","Outcome_cat")
(heat.map.all.itd <- heat.map +
    labs(x="Conservation Intervention", y="Outcome", title ="All ecosystems"))
plot_grid(heat.map.all + labs(title= "all studies"),
          heat.map.all.itd + labs(title= "interdisciplinary studies"))
ggsave(paste0(plotdir,today.date,'_interdisc_int_out_map.png'),width = 16,height = 8)

# Coral
my_heat_map(filter(data_all,coral==1),"Int_cat","Outcome_cat", high.col = "coral3")
io_counts.coral <- io_counts
(heat.map.coral <- heat.map + labs(x="Conservation Intervention", y="Outcome", title ="Coral"))

# Mangrove
my_heat_map(filter(data_all,mangrove==1),"Int_cat","Outcome_cat", high.col = "orange2")
io_counts.mangrove <- io_counts
(heat.map.mangrove <- heat.map + labs(x="Conservation Intervention", y="Outcome", title ="Mangrove")) 

# Seagrass
my_heat_map(filter(data_all,seagrass==1),"Int_cat","Outcome_cat", high.col = "green4")
io_counts.seagrass <- io_counts
(heat.map.seagrass <- heat.map + labs(x="Conservation Intervention", y="Outcome", title ="Seagrass")) 

# Ecosystem maps on same scale
max.val <- max(io_counts.mangrove$n,io_counts.coral$n,io_counts.seagrass$n)
p.ecosystem.all <- plot_grid(heat.map.coral + scale_fill_gradient2(low="#f7fbff",high= "coral3",name="# Cases",na.value="black", limits=c(0,max.val)),
          heat.map.seagrass + scale_fill_gradient2(low="#f7fbff",high= "green4",name="# Cases",na.value="black", limits=c(0,max.val)),
          heat.map.mangrove + scale_fill_gradient2(low="#f7fbff",high= "orange2",name="# Cases",na.value="black", limits=c(0,max.val)),
          labels=letters[1:3], ncol = 3, nrow = 1, hjust=-1, align = "hv")

# Coral
my_heat_map(filter(Eco_Soc_ES_Out,coral==1),"Int_cat","Outcome_cat", high.col = "coral3")
io_counts.coral.itdc <- io_counts
(heat.map.coral.itdc <- heat.map + labs(x="Conservation Intervention", y="Outcome", title ="Coral"))

# Mangrove
my_heat_map(filter(Eco_Soc_ES_Out,mangrove==1),"Int_cat","Outcome_cat", high.col = "orange2")
io_counts.mangrove.itdc <- io_counts
(heat.map.mangrove.itdc <- heat.map + labs(x="Conservation Intervention", y="Outcome", title ="Mangrove")) 

# Seagrass
my_heat_map(filter(Eco_Soc_ES_Out,seagrass==1),"Int_cat","Outcome_cat", high.col = "green4")
io_counts.seagrass.itdc <- io_counts
(heat.map.seagrass.itdc <- heat.map + labs(x="Conservation Intervention", y="Outcome", title ="Seagrass")) 

# Ecosystem maps on same scale
max.val <- max(io_counts.mangrove.itdc$n,io_counts.coral.itdc$n,io_counts.seagrass.itdc$n)
p.ecosystem.all.itdc <- plot_grid(heat.map.coral.itdc + scale_fill_gradient2(low="#f7fbff",high= "coral3",name="# Cases",na.value="black", limits=c(0,max.val)),
          heat.map.seagrass.itdc + scale_fill_gradient2(low="#f7fbff",high= "green4",name="# Cases",na.value="black", limits=c(0,max.val)),
          heat.map.mangrove.itdc + scale_fill_gradient2(low="#f7fbff",high= "orange2",name="# Cases",na.value="black", limits=c(0,max.val)),
          labels=letters[1:3], ncol = 3, nrow = 1, hjust=-1, align = "hv")

plot_grid(p.ecosystem.all,p.ecosystem.all.itdc,nrow=2)
ggsave(paste0(plotdir,today.date,'_interdisc_habitat_int_out_map.png'),width = 17,height = 16)
```

## Multi-intervention & Interdisciplinary outcome sub heat maps
```{r eval=T}

#  INterventions
int.x.count <- data_all %>% 
  select(aid, Int_cat) %>% 
  filter(Int_cat!="" & !is.na(Int_cat)) %>%  # just in case
  arrange(aid,Int_cat) %>% 
  distinct() %>%
  group_by(aid) %>%
  filter(n() > 1) %>%
  split(.$aid) %>%
  map(., 2) %>%
  map(~combn(.x, m = 2)) %>%
  map(~t(.x)) %>%
  map_dfr(as_tibble) %>% 
  group_by(V1,V2) %>% 
  count() %>% 
  rename(Int1=V1,Int2=V2)
  
  int.x.list <- expand.grid(int_list$int_val,int_list$int_val)  %>% 
    rename(Int1=Var1,Int2=Var2)

  int.x.count.full <- int.x.count %>% 
    full_join(int.x.list) %>%   # inserts missing combinations
  #  mutate(n=replace_na(n,0)) %>%
    ungroup() %>% 
    mutate( Int1=factor( Int1,levels=mixedsort(int_list$int_val))  # set int list in right order
 )

ggplot(data=int.x.count.full, aes(x=Int2,y=reorder(Int1, desc(Int1)))) +
    theme_bw() +
    geom_tile(aes(fill = n), color='white',size=0.1) +
    scale_fill_gradient(low = '#f7fbff', high = '#2171b5', space = 'Lab',na.value="white",limits=c(0,max(int.x.count.full$n))) +
    geom_text(aes(label=n),show.legend = T) +
    theme(axis.text.x=element_text(angle=90),
          axis.ticks=element_blank(),
          axis.line=element_blank(),
          panel.border=element_blank(),
          panel.grid.major=element_line(color='#eeeeee'))+
    theme(axis.text.x = element_text(angle=45,hjust=0,vjust=1,size=9)) +
    scale_x_discrete(position = "top") +
    scale_y_discrete(position = "right") +
    labs(x="Intervention 1", y="Intervention 2")
  ggsave(paste0(plotdir,today.date,'_multiple_int_map.png'),width = 8,height = 8)
  
  
# Sub-interventions
sub.int.x.count <- data_all %>% 
    select(aid, Intervention.subcategory) %>% 
    filter(Intervention.subcategory!="" & !is.na(Intervention.subcategory)) %>%  # just in case
    arrange(aid,Intervention.subcategory) %>% 
    distinct() %>%
    group_by(aid) %>%
    filter(n() > 1) %>%
    split(.$aid) %>%
    map(., 2) %>%
    map(~combn(.x, m = 2)) %>%
    map(~t(.x)) %>%
    map_dfr(as_tibble) %>% 
    group_by(V1,V2) %>% 
    count() %>% 
    rename(Int1=V1,Int2=V2)
  
sub.int.x.list <- expand.grid(int_sub_list$int_val,int_sub_list$int_val)  %>% 
    rename(Int1=Var1,Int2=Var2)
  
sub.int.x.count.full <- sub.int.x.count %>% 
    full_join(sub.int.x.list) %>%   # inserts missing combinations
   # mutate(n=replace_na(n,0)) %>%
    ungroup() %>% 
    mutate( Int1=factor( Int1,levels=mixedsort(int_sub_list$int_val))  # set int list in right order
    )
  
ggplot(data=sub.int.x.count.full, aes(x=Int2,y=reorder(Int1, desc(Int1)),fill=n)) +
  theme_bw() +
  geom_tile(aes(fill = n), color='white',size=0.1) +
  scale_fill_gradient(low = '#f7fbff', high = '#2171b5', space = 'Lab',na.value="white",limits=c(0,max(sub.int.x.count.full$n))) +
  geom_text(aes(label=n),show.legend = T) +
  theme(axis.text.x=element_text(angle=90),
        axis.ticks=element_blank(),
        axis.line=element_blank(),
        panel.border=element_blank(),
        panel.grid.major=element_line(color='#eeeeee'))+
  theme(axis.text.x = element_text(angle=45,hjust=0,vjust=1,size=9)) +
  scale_x_discrete(position = "top") +
  scale_y_discrete(position = "right") +
  labs(x="Sub-Intervention 1", y="Sub-Intervention 2")
ggsave(paste0(plotdir,today.date,'_multiple_sub_int_map.png'),width = 12,height = 12)
  
  
# Outcomes
out.x.count <- data_all %>% 
    select(aid, Outcome_cat) %>% 
    filter(Outcome_cat!="" & !is.na(Outcome_cat)) %>%  # just in case
    arrange(aid,Outcome_cat) %>% 
    distinct() %>%
    group_by(aid) %>%
    filter(n() > 1) %>%
    split(.$aid) %>%
    map(., 2) %>%
    map(~combn(.x, m = 2)) %>%
    map(~t(.x)) %>%
    map_dfr(as_tibble) %>% 
    group_by(V1,V2) %>% 
    count() %>% 
    rename(Out1=V1,Out2=V2)
  
  out.x.list <- expand.grid(out_list$out_val,out_list$out_val)  %>% 
    rename(Out1=Var1,Out2=Var2)
  
  out.x.count.full <- out.x.count %>% 
    full_join(out.x.list) %>%   # inserts missing combinations
  #  mutate(n=replace_na(n,0)) %>%
    ungroup() %>% 
    mutate(Out1=factor(Out1,levels=mixedsort(out_list$out_val))  # set Out list in right order
    )
  ggplot(data=out.x.count.full, aes(x=Out2,y=reorder(Out1, desc(Out1)),fill=n)) +
    theme_bw() +
    geom_tile(aes(fill = n), color='white',size=0.1) +
    scale_fill_gradient(low = '#f7fbff', high = '#2171b5', space = 'Lab',na.value="white",limits=c(0,max(sub.int.x.count.full$n))) +
    geom_text(aes(label=n),show.legend = T) +
    theme(axis.text.x=element_text(angle=90),
          axis.ticks=element_blank(),
          axis.line=element_blank(),
          panel.border=element_blank(),
          panel.grid.major=element_line(color='#eeeeee'))+
    theme(axis.text.x = element_text(angle=45,hjust=0,vjust=1,size=9)) +
    scale_x_discrete(position = "top") +
    scale_y_discrete(position = "right") +
    labs(x="Outcome 1", y="Outcome 2")
  
ggsave(paste0(plotdir,today.date,'_multiple_out_map.png'),width = 8,height = 8)
  
  
  # sub-outcomes
sub.out.x.count <- data_all %>% 
    select(aid, Outcome.subcategory) %>% 
    filter(Outcome.subcategory!="" & !is.na(Outcome.subcategory)) %>%  # just in case
    arrange(aid,Outcome.subcategory) %>% 
    distinct() %>%
    group_by(aid) %>%
    filter(n() > 1) %>%
    split(.$aid) %>%
    map(., 2) %>%
    map(~combn(.x, m = 2)) %>%
    map(~t(.x)) %>%
    map_dfr(as_tibble) %>% 
    group_by(V1,V2) %>% 
    count() %>% 
    rename(Out1=V1,Out2=V2)
  
sub.out.x.list <- expand.grid(out_sub_list$out_val,out_sub_list$out_val)  %>% 
    rename(Out1=Var1,Out2=Var2)
  
sub.out.x.count.full <- sub.out.x.count %>% 
    full_join(sub.out.x.list) %>%   # inserts missing combinations
  #  mutate(n=replace_na(n,0)) %>%
    ungroup() %>% 
    mutate(Out1=factor(Out1,levels=mixedsort(out_sub_list$out_val))  # set Out list in right order
    )

ggplot(data=sub.out.x.count.full, aes(x=Out2,y=reorder(Out1, desc(Out1)),fill=n)) +
    theme_bw() +
    geom_tile(aes(fill = n), color='white',size=0.1) +
    scale_fill_gradient(low = '#f7fbff', high = '#2171b5', space = 'Lab',na.value="white",limits=c(0,max(sub.int.x.count.full$n))) +
    geom_text(aes(label=n),show.legend = T) +
    theme(axis.text.x=element_text(angle=90),
          axis.ticks=element_blank(),
          axis.line=element_blank(),
          panel.border=element_blank(),
          panel.grid.major=element_line(color='#eeeeee'))+
    theme(axis.text.x = element_text(angle=45,hjust=0,vjust=1,size=9)) +
    scale_x_discrete(position = "top") +
    scale_y_discrete(position = "right") +
    labs(x="Outcome 1", y="Outcome 2") 
  
ggsave(paste0(plotdir,today.date,'_multiple_out_map.png'),width = 18,height = 18)
  
# Interdisciplinary sub outcomes
sub.out.x.count.intdisc <- sub.out.x.count.full %>% 
  filter(str_detect(Out1, "^[1234]") & str_detect(Out2, "^[4567]") )
unique(sub.out.x.count.intdisc$Out1)
unique(sub.out.x.count.intdisc$Out2)

ggplot(data=sub.out.x.count.intdisc, aes(x=Out1,y=reorder(Out2, desc(Out2)),fill=n)) +
    theme_bw() +
    geom_tile(aes(fill = n), color='white',size=0.1) +
    scale_fill_gradient(low = '#f7fbff', high = '#2171b5', space = 'Lab',na.value="white",limits=c(0,max(sub.int.x.count.full$n))) +
    geom_text(aes(label=n),show.legend = T) +
    theme(axis.text.x=element_text(angle=90),
          axis.ticks=element_blank(),
          axis.line=element_blank(),
          panel.border=element_blank(),
          panel.grid.major=element_line(color='#eeeeee'))+
    theme(axis.text.x = element_text(angle=45,hjust=0,vjust=1,size=9)) +
    scale_x_discrete(position = "top") +
    scale_y_discrete(position = "right") +
    labs(x="Ecological + Ecosystem services", y= "Social + Ecosystem services")
  
ggsave(paste0(plotdir,today.date,'interdisc_multiple_out_map.png'),width = 11,height = 8)
  

# Multi-intervention interdiscpl-outcomes
# id multi-intervention studies
mi.aid <- data_all %>%
  group_by(aid,Int_cat) %>% 
  summarise %>% 
  group_by(aid) %>% 
  filter(n()>1) %>% 
  distinct(aid) %>% 
  pull(aid)

mi.sub.out.x.count <- data_all %>% 
  filter(aid%in%mi.aid) %>% 
    select(aid, Outcome.subcategory) %>% 
    filter(Outcome.subcategory!="" & !is.na(Outcome.subcategory)) %>%  # just in case
    arrange(aid,Outcome.subcategory) %>% 
    distinct() %>%
    group_by(aid) %>%
    filter(n() > 1) %>%
    split(.$aid) %>%
    map(., 2) %>%
    map(~combn(.x, m = 2)) %>%
    map(~t(.x)) %>%
    map_dfr(as_tibble) %>% 
    group_by(V1,V2) %>% 
    count() %>% 
    rename(Out1=V1,Out2=V2)
  
mi.sub.out.x.list <- expand.grid(out_sub_list$out_val,out_sub_list$out_val)  %>% 
    rename(Out1=Var1,Out2=Var2)
  
mi.sub.out.x.count.interdisc <- sub.out.x.count %>% 
    full_join(sub.out.x.list) %>%   # inserts missing combinations
  #  mutate(n=replace_na(n,0)) %>%
    ungroup() %>% 
    mutate(Out1=factor(Out1,levels=mixedsort(out_sub_list$out_val))  # set Out list in right order
    ) %>% 
    filter(str_detect(Out1, "^[1234]") & str_detect(Out2, "^[4567]") ) # interdisciplinary only


ggplot(data=mi.sub.out.x.count.interdisc, aes(x=Out2,y=reorder(Out1, desc(Out1)),fill=n)) +
    theme_bw() +
    geom_tile(aes(fill = n), color='white',size=0.1) +
    scale_fill_gradient(low = '#f7fbff', high = '#2171b5', space = 'Lab',na.value="white",limits=c(0,max(sub.int.x.count.full$n))) +
    geom_text(aes(label=n),show.legend = T) +
    theme(axis.text.x=element_text(angle=90),
          axis.ticks=element_blank(),
          axis.line=element_blank(),
          panel.border=element_blank(),
          panel.grid.major=element_line(color='#eeeeee'))+
    theme(axis.text.x = element_text(angle=45,hjust=0,vjust=1,size=9)) +
    scale_x_discrete(position = "top") +
    scale_y_discrete(position = "right") +
    labs(x="Outcome 1", y="Outcome 2") 
  
ggsave(paste0(plotdir,today.date,'_multi-intervention_multiple_out_map.png'),width = 18,height = 18)



#--- Chord diagram
chord.dat <- data_all %>% 
  filter(interdisc.aid==1) %>% 
  group_by(Int_cat,Outcome_cat) %>% 
  summarise(value=n_distinct(aid))

# original
pacman::p_load(circlize)
chordDiagram(chord.dat)
circos.clear()

# rotate labels (prob easier to reduce them)
png(paste0(plotdir,today.date,'_multi-intervention_multiple_out_chord.png'), width = 10, height = 8, units = "in", res=600) 
chordDiagram(chord.dat, annotationTrack = "grid", 
    preAllocateTracks = list(track.height = max(strwidth(unlist(dimnames(chord.dat))))))
# we go back to the first track and customize sector labels
circos.track(track.index = 1, panel.fun = function(x, y) {
    circos.text(CELL_META$xcenter, CELL_META$ylim[1], CELL_META$sector.index, 
        facing = "clockwise", niceFacing = TRUE, adj = c(0, 0.5))
}, bg.border = NA) 
dev.off()


# rotate labels (prob easier to reduce them)
png(paste0(plotdir,today.date,'_multi-intervention_multiple_out_chord_reverse.png'), width = 10, height = 8, units = "in", res=600) 
chordDiagram(select(chord.dat,Outcome_cat,Int_cat,value), annotationTrack = "grid", 
    preAllocateTracks = list(track.height = max(strwidth(unlist(dimnames(chord.dat))))))
# we go back to the first track and customize sector labels
circos.track(track.index = 1, panel.fun = function(x, y) {
    circos.text(CELL_META$xcenter, CELL_META$ylim[1], CELL_META$sector.index, 
        facing = "clockwise", niceFacing = TRUE, adj = c(0, 0.5))
}, bg.border = NA) 
dev.off()


```


7. Time periods

IN PROGRESS

```{r eval=T}

# Extra: Time Period:

  # % of studies after 2000
  # % of studies in the year:....
  # % of studies in [specific intervention area] during [specific time]
  
  # % of studies in top 2 interventions (cons desig and spec management) 
    # during [specific time]
  
  # could do ^ for outcome, could also try to get a chart that gives # of each
    # intervention and outcome for each year. Should be able to do this!


# make barplot
test.dat <- data_all %>%
            group_by(Outcome_cat) %>% 
            summarise(num=n_distinct(aid), pct=num/num.studies)
ggplot(test.dates(Outcome_cat,num)) +
  geom_bar(stat = )
